{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods (Pt A - Requires Update)\n",
    "1. Import the data set. \n",
    "2. Clean and wrangle data set to have a tidydata format\n",
    "3. Visualize relationships between variables of interest: \n",
    "\n",
    "    A. Investment Activity vs Label (<= 50k, > 50k annual income) \n",
    "        a. Bar graph \n",
    "        b. X-Axis: Label \n",
    "        c. Y-Axis: Count of Capital Gains and Capital Losses \n",
    "    B. Capital Gains vs Age \n",
    "        a. Scatter plot \n",
    "        b. X-Axis: Age \n",
    "        c. Y-Axis: Capital Gains (USD) \n",
    "    C. Working Hours per Week vs Age \n",
    "        a. Scatter plot \n",
    "        b. X-Axis: Age \n",
    "        c. Y-Axis: Working Hours per Week \n",
    "4. Summarize the data set and address class imbalance if one label is more prevalent then the other. \n",
    "\n",
    "## Methods (Pt B)\n",
    "1. Tune our classification model (k-nearest neighbours) using predictors of interest.\n",
    "\n",
    "    A. Our dataset provided training and testing data, so we do not have to split our data set. \n",
    "    \n",
    "    B. Pre-process our training data (standardize, center and upsample for class imbalance). \n",
    "    \n",
    "    C. Create a 5 fold cross validation data split using vfold. \n",
    "    \n",
    "    D. Determine specifications for the nearest neighbour function. \n",
    "    \n",
    "        a. weight_func = \"rectangular\" \n",
    "        b. neighbors = tune() \n",
    "    E. Fit our model for each fold in our cross validation. \n",
    "    \n",
    "        a. tune_grid(resamples=vold,grid=10) \n",
    "    F. Create a scatter plot of Accuracy vs k to determine the best k \n",
    "    \n",
    "2. Retrain our classification model (k-nearest neighbours) using our tuned k value and predictors of interest. \n",
    "3. Predict labels on our testing data aset and evaluate the estimated accuracy of our classification model.  \n",
    "4. Create a bar chart to visualize our results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning our Classification Model\n",
    "### Selecting Relevant Data\n",
    "From our analysis above, we have determined capital gain as the most suitable predictor for predicting our label. \\\n",
    "Our first step is to select the relevant columns we need from the tidy format of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in adult_tidy %>% select(label, capital_gain): could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in adult_tidy %>% select(label, capital_gain): could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "set.seed(1000)\n",
    "## Selecting Relevant Data\n",
    "adult_relevant <- adult_tidy %>%\n",
    "    select(label, capital_gain)\n",
    "\n",
    "head(adult_relevant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize, Center and Upsample\n",
    "In this step we normalize our data to have values between [-1,1] and centered around 0. \\\n",
    "We also upsample to mitigate the class imbalance in our data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardize, Center and Upsample\n",
    "adult_recipe <- recipe(label~capital_gain,data=adult_relevant) %>%\n",
    "    step_scale(all_predictors()) %>%\n",
    "    step_center(all_predictors()) %>%\n",
    "    step_upsample(label, over_ratio = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Knn Model\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>%\n",
    "  set_engine(\"kknn\") %>%\n",
    "  set_mode(\"classification\")\n",
    "knn_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "For tuning, we will be using 5 fold cross validation. \\\n",
    "This will shuffle our data into 5 different sets and allow us to compute the average accuracy.\\\n",
    "Cross validation is used have a more representative accuracy as it is not based off of one set of data. \\\n",
    "We have chosen 5 and not a higher C value due to our large dataset. \\\n",
    "Increasing C will drastically increase the expensiveness of tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in vfold_cv(adult_relevant, v = 5, strata = label): could not find function \"vfold_cv\"\n",
     "output_type": "error",
     "traceback": [
      "Error in vfold_cv(adult_relevant, v = 5, strata = label): could not find function \"vfold_cv\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "## Cross Validation\n",
    "adult_vfold <- vfold_cv(adult_relevant, v = 5, strata = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Results of Tuning \n",
    "knn_results <- workflow() %>%\n",
    "    add_recipe(adult_recipe)%>%\n",
    "    add_model(knn_spec)%>%\n",
    "    tune_grid(resamples = adult_vfold, grid = 20)%>%\n",
    "    collect_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs K Nearest Neighbours\n",
    "We plot accuracy vs K nearest neighbours to visualize the minimum K that will yield the highest accuracy.\n",
    "From our plot we will choose K = 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy vs K Plot\n",
    "accuracies <- knn_results %>%\n",
    "  filter(.metric == \"accuracy\")\n",
    "\n",
    "accuracy_vs_k <- ggplot(accuracies, aes(x = neighbors, y = mean)) +\n",
    "  geom_point() +\n",
    "  geom_line() +\n",
    "  labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "  theme(text = element_text(size = 18))\n",
    "\n",
    "accuracy_vs_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Our Classifier\n",
    "In this step we will retrain our Knn model with our optimal K value, K = 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Knn Model\n",
    "knn_spec_2 <- nearest_neighbor(weight_func=\"rectangular\", neighbors=11) %>%\n",
    "    set_engine(\"kknn\") %>%\n",
    "    set_mode(\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit Model\n",
    "knn_results_2 <- workflow() %>%\n",
    "    add_recipe(adult_recipe)%>%\n",
    "    add_model(knn_spec_2)%>%\n",
    "    fit(data = adult_testing_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Our Classifier\n",
    "Now that we have our trained classifier, we will predict labels using our tidied test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Testing Data Set\n",
    "adult_testing <- read_delim(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", delim=\",\",col_names=c(\"age\", \"workclass\", \"fnl_wgt\",\"education\",\n",
    "    \"education_num\",\"marital_status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital_gain\",\"capital_loss\",\n",
    "    \"hrs_per_week\",\"native_country\",\"label\"))\n",
    "\n",
    "head(adult_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning and Wrangling Testing Data\n",
    "adult_testing_tidy <- adult_testing %>%\n",
    "    mutate(label=as_factor(label), capital_gain = as.numeric(capital_gain)) %>%\n",
    "    filter_all(all_vars(. != \" ?\")) %>%\n",
    "    select(capital_gain,label)\n",
    "\n",
    "head(adult_testing_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Labels\n",
    "adult_test_predictions <- predict(knn_results_2, adult_testing_tidy) %>%\n",
    "       bind_cols(adult_testing_tidy)\n",
    "\n",
    "head(adult_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Accuracy\n",
    "We now try to evaluate the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in adult_test_predictions %>% metrics(truth = label, estimate = .pred_class): could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in adult_test_predictions %>% metrics(truth = label, estimate = .pred_class): could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "## Accuracy\n",
    "adult_prediction_accuracy <- adult_test_predictions %>%\n",
    "         metrics(truth = label, estimate = .pred_class)             \n",
    "\n",
    "adult_prediction_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Table showing the number of correct and incorrect classifications for each label\n",
    "\n",
    "accuracy_summary <- adult_test_predictions %>%\n",
    "    conf_mat(truth = label, estimate = .pred_class)\n",
    "\n",
    "accuracy_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot of the accuracy percentages\n",
    "adult_test_predictions$accurate <- ifelse(adult_test_predictions$.pred_class == adult_test_predictions$label, \"Yes\", \"No\")\n",
    "\n",
    "options(repr.plot.width = 10, repr.plot.height = 10)\n",
    "accurate_plot <- adult_test_predictions %>%\n",
    "    ggplot(aes(x = label, fill = accurate)) + \n",
    "    geom_bar(position = 'fill') + \n",
    "    xlab(\"Income Catergory\") +\n",
    "    ylab(\"Proportion\") +\n",
    "    labs(fill = \"Was the Classification Accurate\") +\n",
    "    ggtitle(\"Proportion of Accurate Predictions\") +\n",
    "    theme(text = element_text(size = 20))\n",
    "\n",
    "accurate_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Classification\n",
    "Our model yields an accuracy of 80.5%. However, we can see from the table and accuracy plot that a large proportion of >=50k labels are being predicted inaccurately. \\\n",
    "The high accuracy is driven by an unbalanced testing data set where we have significantly more data points with labels <50k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
