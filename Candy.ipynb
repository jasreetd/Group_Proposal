{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods (Pt A - Requires Update)\n",
    "1. Import the data set. \n",
    "2. Clean and wrangle data set to have a tidydata format\n",
    "3. Visualize relationships between variables of interest: \n",
    "\n",
    "    A. Investment Activity vs Label (<= 50k, > 50k annual income) \n",
    "        a. Bar graph \n",
    "        b. X-Axis: Label \n",
    "        c. Y-Axis: Count of Capital Gains and Capital Losses \n",
    "    B. Capital Gains vs Age \n",
    "        a. Scatter plot \n",
    "        b. X-Axis: Age \n",
    "        c. Y-Axis: Capital Gains (USD) \n",
    "    C. Working Hours per Week vs Age \n",
    "        a. Scatter plot \n",
    "        b. X-Axis: Age \n",
    "        c. Y-Axis: Working Hours per Week \n",
    "4. Summarize the data set and address class imbalance if one label is more prevalent then the other. \n",
    "\n",
    "## Methods (Pt B)\n",
    "1. Tune our classification model (k-nearest neighbours) using predictors of interest.\n",
    "\n",
    "    A. Our dataset provided training and testing data, so we do not have to split our data set. \n",
    "    \n",
    "    B. Pre-process our training data (standardize, center and upsample for class imbalance). \n",
    "    \n",
    "    C. Create a 5 fold cross validation data split using vfold. \n",
    "    \n",
    "    D. Determine specifications for the nearest neighbour function. \n",
    "    \n",
    "        a. weight_func = \"rectangular\" \n",
    "        b. neighbors = tune() \n",
    "    E. Fit our model for each fold in our cross validation. \n",
    "    \n",
    "        a. tune_grid(resamples=vold,grid=10) \n",
    "    F. Create a scatter plot of Accuracy vs k to determine the best k \n",
    "    \n",
    "2. Retrain our classification model (k-nearest neighbours) using our tuned k value and predictors of interest. \n",
    "3. Predict labels on our testing data aset and evaluate the estimated accuracy of our classification model.  \n",
    "4. Create a bar chart to visualize our results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning our Classification Model\n",
    "### Selecting Relevant Data\n",
    "From our analysis above, we have determined capital gain as the most suitable predictor for predicting our label. \\\n",
    "Our first step is to select the relevant columns we need from the tidy format of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in adult_tidy %>% select(label, capital_gain): could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in adult_tidy %>% select(label, capital_gain): could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "set.seed(2000)\n",
    "## Selecting Relevant Data\n",
    "adult_relevant <- adult_tidy %>%\n",
    "    select(label, capital_gain)\n",
    "\n",
    "head(adult_relevant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize, Center and Upsample\n",
    "In this step we normalize our data to have values between [-1,1] and centered around 0. \\\n",
    "We also upsample to mitigate the class imbalance in our data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardize, Center and Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Knn Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "For tuning, we will be using 5 fold cross validation. \\\n",
    "This will shuffle our data into 5 different sets and allow us to compute the average accuracy.\\\n",
    "Cross validation is used have a more reprsentative accuracy as it is not based off of one set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in vfold_cv(adult_relevant, v = 5, strata = label): could not find function \"vfold_cv\"\n",
     "output_type": "error",
     "traceback": [
      "Error in vfold_cv(adult_relevant, v = 5, strata = label): could not find function \"vfold_cv\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "## Cross Validation\n",
    "adult_vfold <- vfold_cv(adult_relevant, v = 5, strata = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Results of Tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs K Nearest Neighbours\n",
    "We plot accuracy vs K nearest neighbours to visualize the minimum K that will yield the highest accuracy.\n",
    "From our plot we will choose K = 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy vs K Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining Our Classifier\n",
    "In this step we will retrain our Knn model with our optimal K value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Knn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Our Classifier\n",
    "Now that we have our trained classifier, we will predict labels using our tidied test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tidy Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizing Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
